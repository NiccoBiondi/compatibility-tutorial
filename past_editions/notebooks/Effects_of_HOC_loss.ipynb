{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbvTioQbCQWx"
      },
      "source": [
        "# Higher-order (HOC) vs First-order (CE) loss\n",
        "\n",
        "In this code session, we will see how the higher-order dependencies captured by the HOC loss allow providing more useful information to be learned during a model fine-tuning with respect to the ce loss which captures only first-order statistics.\n",
        "\n",
        "Code inspired from:\n",
        "- https://github.com/NiccoBiondi/CompatibleLifelongRepresentation\n",
        "- https://github.com/miccunifi/iamcl2r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jxIEFd7427Zj"
      },
      "outputs": [],
      "source": [
        "# !pip install --quiet continuum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z4RlkxWK2i1_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from collections import defaultdict as dd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import BatchSampler\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "from continuum import ClassIncremental\n",
        "from continuum.datasets import MNIST\n",
        "from continuum import rehearsal\n",
        "\n",
        "# reproducibility\n",
        "seed = 42\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBMbQwwzqnyk"
      },
      "source": [
        "### Utility functions\n",
        "\n",
        "Net and useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oY52ImNc2ejD"
      },
      "outputs": [],
      "source": [
        "# model lenetpp + polygon2d\n",
        "\"\"\"\n",
        "    LeNet++ as described in the Center Loss paper.\n",
        "\"\"\"\n",
        "class LeNet(nn.Module):\n",
        "    # to create a 2D polygonal shape with num_classes sides\n",
        "    def __init__(self, num_classes=10, feat_dim=64, batch_norm=True, **kwargs):\n",
        "        self.enable_batch_norm = batch_norm\n",
        "        self.feat_dim = feat_dim\n",
        "        self.fixed = kwargs.get('fixed', True)\n",
        "\n",
        "        activation_function = nn.ReLU\n",
        "\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(1, 32, 5, stride=1, padding=2)\n",
        "        self.batch_norm1_1 = nn.BatchNorm2d(32)\n",
        "        self.act1_1 = activation_function()\n",
        "\n",
        "        self.conv1_2 = nn.Conv2d(32, 32, 5, stride=1, padding=2)\n",
        "        self.batch_norm1_2 = nn.BatchNorm2d(32)\n",
        "        self.act1_2 = activation_function()\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(32, 64, 5, stride=1, padding=2)\n",
        "        self.batch_norm2_1 = nn.BatchNorm2d(64)\n",
        "        self.act2_1 = activation_function()\n",
        "\n",
        "        self.conv2_2 = nn.Conv2d(64, 64, 5, stride=1, padding=2)\n",
        "        self.batch_norm2_2 = nn.BatchNorm2d(64)\n",
        "        self.act2_2 = activation_function()\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(64, 128, 5, stride=1, padding=2)\n",
        "        self.batch_norm3_1 = nn.BatchNorm2d(128)\n",
        "        self.act3_1 = activation_function()\n",
        "\n",
        "        self.conv3_2 = nn.Conv2d(128, 128, 5, stride=1, padding=2)\n",
        "        self.batch_norm3_2 = nn.BatchNorm2d(128)\n",
        "        self.act3_2 = activation_function()\n",
        "\n",
        "        if self.fixed:\n",
        "            self.fc = nn.Linear(128 * 3 * 3, feat_dim, bias=False)\n",
        "            self.fc2 = nn.Linear(feat_dim, num_classes, bias=False)\n",
        "\n",
        "            fixed_weights = self.simplex_coordinates(num_classes=num_classes)\n",
        "            self.fc2.weight.requires_grad = False  # set no gradient for the fixed classifier\n",
        "            self.fc2.weight.copy_(fixed_weights)   # set the weights for the classifier\n",
        "        else:\n",
        "            self.fc2 = nn.Linear(128 * 3 * 3, num_classes, bias=False)\n",
        "\n",
        "    @property\n",
        "    def feature_input_size(self):\n",
        "        return 128 * 3 * 3\n",
        "\n",
        "    def forward(self, x, ind=None):\n",
        "        if self.enable_batch_norm:\n",
        "            out = self.act1_1(self.batch_norm1_1(self.conv1_1(x)))\n",
        "            out = self.act1_2(self.batch_norm1_2(self.conv1_2(out)))\n",
        "        else:\n",
        "            out = self.act1_1(self.conv1_1(x))\n",
        "            out = self.act1_2(self.conv1_2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "\n",
        "        if self.enable_batch_norm:\n",
        "            out = self.act2_1(self.batch_norm2_1(self.conv2_1(out)))\n",
        "            out = self.act2_2(self.batch_norm2_2(self.conv2_2(out)))\n",
        "        else:\n",
        "            out = self.act2_1(self.conv2_1(out))\n",
        "            out = self.act2_2(self.conv2_2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        if self.enable_batch_norm:\n",
        "            out = self.act3_1(self.batch_norm3_1(self.conv3_1(out)))\n",
        "            out = self.act3_2(self.batch_norm3_2(self.conv3_2(out)))\n",
        "        else:\n",
        "            out = self.act3_1(self.conv3_1(out))\n",
        "            out = self.act3_2(self.conv3_2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        embeddings = out.view(-1, 128 * 3 * 3)\n",
        "\n",
        "        if self.fixed:\n",
        "            embeddings = self.fc(embeddings)\n",
        "        out = self.fc2(embeddings)\n",
        "\n",
        "        return embeddings, out\n",
        "\n",
        "    def simplex_coordinates(self, num_classes=10):\n",
        "        m = num_classes - 1\n",
        "        # add the credit\n",
        "\n",
        "        x = np.zeros([m, m + 1])\n",
        "        for j in range(0, m):\n",
        "            x[j, j] = 1.0\n",
        "\n",
        "        a = (1.0 - np.sqrt(float(1 + m))) / float(m)\n",
        "\n",
        "        for i in range(0, m):\n",
        "            x[i, m] = a\n",
        "\n",
        "        #  Adjust coordinates so the centroid is at zero.\n",
        "        c = np.zeros(m)\n",
        "        for i in range(0, m):\n",
        "            s = 0.0\n",
        "            for j in range(0, m + 1):\n",
        "                s = s + x[i, j]\n",
        "            c[i] = s / float(m + 1)\n",
        "\n",
        "        for j in range(0, m + 1):\n",
        "            for i in range(0, m):\n",
        "                x[i, j] = x[i, j] - c[i]\n",
        "\n",
        "        #  Scale so each column has norm 1. UNIT NORMALIZED\n",
        "        s = 0.0\n",
        "        for i in range(0, m):\n",
        "            s = s + x[i, 0] ** 2\n",
        "        s = np.sqrt(s)\n",
        "\n",
        "        for j in range(0, m + 1):\n",
        "            for i in range(0, m):\n",
        "                x[i, j] = x[i, j] / s\n",
        "\n",
        "        return torch.Tensor(x.transpose())\n",
        "\n",
        "def create_lenet(resume_path=None, starting_classes=10, feat_size=64, device=0, **kwargs):\n",
        "    model = LeNet(num_classes=starting_classes, feat_dim=feat_size, **kwargs)\n",
        "    if resume_path not in [None, '']:\n",
        "        new_pretrained_dict = torch.load(resume_path, map_location='cpu')\n",
        "        model.load_state_dict(new_pretrained_dict)\n",
        "\n",
        "    model.cuda(device)\n",
        "\n",
        "    return model\n",
        "\n",
        "def l2_norm(input, axis=1):\n",
        "    norm = torch.norm(input, 2, axis, True)\n",
        "    output = torch.div(input, norm)\n",
        "\n",
        "    return output\n",
        "\n",
        "class BalancedBatchSampler(BatchSampler):\n",
        "    def __init__(self, dataset, batch_size, n_classes, n_samples, seen_classes, rehearsal=0):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.n_classes = n_classes\n",
        "        self.n_samples = n_samples\n",
        "        self.seen_classes = seen_classes\n",
        "        self.rehearsal = rehearsal\n",
        "        self.n_batches = self.n_samples // self.batch_size # drop last\n",
        "        if self.n_batches == 0:\n",
        "            self.n_batches = 1\n",
        "            self.size = self.n_samples if rehearsal == 0 else self.n_samples//2\n",
        "        elif rehearsal == 0:\n",
        "            self.size = self.batch_size\n",
        "        else:\n",
        "            self.size = self.batch_size//2\n",
        "        self.index_dic = dd(list)\n",
        "        self.indices = []\n",
        "        self.seen_indices = []\n",
        "        for index, y in enumerate(self.dataset._y):\n",
        "            if y not in self.seen_classes:\n",
        "                self.indices.append(index)\n",
        "            else:\n",
        "                self.seen_indices.append(index)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.n_batches):\n",
        "            batch = []\n",
        "            if self.rehearsal > 0:\n",
        "                replace = True if len(self.seen_indices) <= self.size else False\n",
        "                batch.extend(np.random.choice(self.seen_indices, size=self.size, replace=replace))\n",
        "            replace = True if len(self.indices) <= self.size else False\n",
        "            batch.extend(np.random.choice(self.indices, size=self.size, replace=replace))\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_batches\n",
        "\n",
        "class AverageMeter(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_caUyyuR7nn-"
      },
      "source": [
        "## Higher-order Compatibility (HOC) Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tz4yRSSO5J0B"
      },
      "outputs": [],
      "source": [
        "class HocLoss(nn.Module):\n",
        "    def __init__(self, mu_):\n",
        "        super(HocLoss, self).__init__()\n",
        "        self.mu_ = mu_\n",
        "\n",
        "    def forward(self,\n",
        "                feat_new,\n",
        "                feat_old,\n",
        "                labels,\n",
        "               ):\n",
        "        loss = self._loss(feat_old, feat_new, labels)\n",
        "        return loss\n",
        "\n",
        "    def _loss(self, feat_old, feat_new, labels):\n",
        "        ground_truth = torch.arange(len(labels)).type_as(labels).long()\n",
        "        old_new_logits = self.mu_ * ( feat_old @ feat_new.t() )\n",
        "        loss = F.cross_entropy(old_new_logits, ground_truth)\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5LvHHXjwLQW"
      },
      "source": [
        "## Training Loop\n",
        "2 tasks:\n",
        "- first 5 MNIST classes\n",
        "- second 5 MNIST classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6lmv2MJQApH-"
      },
      "outputs": [],
      "source": [
        "def compute_loss_values(hoc_enabled, batch_size=64, nb_epochs=5, device='cuda'):\n",
        "\n",
        "    print(f\"Loading Training Dataset\")\n",
        "    train_transform = [transforms.RandomCrop(28, padding=4),\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ]\n",
        "\n",
        "    val_transform = [transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ]\n",
        "    dataset_train = MNIST('../data', train=True, download=True)\n",
        "\n",
        "    # create task-sets for lifelong learning\n",
        "    scenario_train = ClassIncremental(dataset_train,\n",
        "                                      initial_increment=5,\n",
        "                                      increment=5,\n",
        "                                      transformations=train_transform)\n",
        "\n",
        "    num_classes = scenario_train.nb_classes\n",
        "    nb_tasks = scenario_train.nb_tasks\n",
        "\n",
        "    # create episodic memory dataset\n",
        "    memory = rehearsal.RehearsalMemory(memory_size=200,\n",
        "                                        herding_method=\"random\",\n",
        "                                        fixed_memory=True,\n",
        "                                        nb_total_classes=10\n",
        "                                    )\n",
        "\n",
        "    feat_size = num_classes - 1\n",
        "    if hoc_enabled:\n",
        "        add_loss = HocLoss(mu_=10)\n",
        "    else:\n",
        "        add_loss = None\n",
        "\n",
        "    best_acc = 0\n",
        "    for task_id, train_task_set in enumerate(scenario_train):\n",
        "\n",
        "        rp = None if task_id == 0 else ckpt_path\n",
        "        new_data_ids = train_task_set.get_classes()\n",
        "\n",
        "        net = create_lenet(resume_path=rp,\n",
        "                            starting_classes=num_classes,\n",
        "                            feat_size=feat_size,\n",
        "                            device=device)\n",
        "\n",
        "        if task_id > 0:\n",
        "            previous_net = create_lenet(resume_path=ckpt_path,\n",
        "                                        starting_classes=num_classes,\n",
        "                                        feat_size=feat_size,\n",
        "                                        device=device)\n",
        "            previous_net.eval()\n",
        "        else:\n",
        "            previous_net = None\n",
        "\n",
        "        lr = 0.1\n",
        "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-04)\n",
        "        scheduler_lr = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=nb_epochs, eta_min=0.00001)\n",
        "        criterion_cls = nn.CrossEntropyLoss().cuda(device)\n",
        "\n",
        "        if task_id > 0:\n",
        "            mem_x, mem_y, mem_t = memory.get()\n",
        "            train_task_set.add_samples(mem_x, mem_y, mem_t)\n",
        "            batchsampler = BalancedBatchSampler(train_task_set, n_classes=train_task_set.nb_classes,\n",
        "                                                batch_size=batch_size, n_samples=len(train_task_set._x),\n",
        "                                                seen_classes=seen_classes)\n",
        "            train_loader = DataLoader(train_task_set, batch_sampler=batchsampler, num_workers=2)\n",
        "        else:\n",
        "            train_loader = DataLoader(train_task_set, batch_size=batch_size, shuffle=True,\n",
        "                                      drop_last=True, num_workers=2)\n",
        "        print(f\"Task {task_id+1} / {scenario_train.nb_tasks}\", end=\"\\r\")\n",
        "        loss_vals = []\n",
        "        for epoch in range(nb_epochs):\n",
        "            loss_vals.append(train_one_epoch(net, train_loader, optimizer, epoch, criterion_cls,\n",
        "                                  previous_net, add_loss, hoc_enabled=hoc_enabled)\n",
        "            )\n",
        "            scheduler_lr.step()\n",
        "\n",
        "        memory.add(*scenario_train[task_id].get_raw_samples(), z=None)\n",
        "        seen_classes = torch.tensor(list(memory.seen_classes), device=device)\n",
        "\n",
        "        ckpt_path = f'{\"../output/HOC\" if hoc_enabled and task_id > 0 else \"../output/SCE\"}_classifier_task_{task_id+1}.pth'\n",
        "        torch.save(net.state_dict(), ckpt_path)\n",
        "\n",
        "    return loss_vals\n",
        "\n",
        "\n",
        "def train_one_epoch(net, train_loader, optimizer, epoch, criterion_cls, \n",
        "                    previous_net, add_loss, hoc_enabled, device='cuda'):\n",
        "\n",
        "    loss_meter = AverageMeter()\n",
        "\n",
        "    net.train()\n",
        "    for bid, batchdata in enumerate(train_loader):\n",
        "\n",
        "        inputs = batchdata[0].cuda(device)\n",
        "        targets = batchdata[1].cuda(device)\n",
        "\n",
        "        feature, output = net(inputs)\n",
        "        loss = criterion_cls(output, targets)\n",
        "\n",
        "        if previous_net is not None and hoc_enabled:\n",
        "            with torch.no_grad():\n",
        "                feature_old, logits_old = previous_net(inputs)\n",
        "            norm_feature_old, norm_feature_new = l2_norm(feature_old), l2_norm(feature)\n",
        "            loss_feat = add_loss(norm_feature_new, norm_feature_old, targets)\n",
        "            loss = loss * 0.5 + (1 - 0.5) * loss_feat\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_meter.update(loss.item(), inputs.size(0))\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss_meter.avg}\", end=\"\\r\")\n",
        "    return loss_meter.avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2P4uMO6gpFU",
        "outputId": "f65b15aa-2229-440d-f7ae-4911c6ccf062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Training Dataset\n",
            "Task 1 / 2\n",
            "Epoch 1, Loss: 0.6255906717715372\n",
            "Epoch 2, Loss: 0.08682628903317822\n",
            "Epoch 3, Loss: 0.05924923849271642\n",
            "Epoch 4, Loss: 0.049081240716842334\n",
            "Epoch 5, Loss: 0.043954216684438836\n",
            "Epoch 6, Loss: 0.04159169332864675\n",
            "Epoch 7, Loss: 0.0416078578319574\n",
            "Epoch 8, Loss: 0.03511569335834838\n",
            "Epoch 9, Loss: 0.03459659141973518\n",
            "Epoch 10, Loss: 0.03482119257259377\n",
            "Epoch 11, Loss: 0.032857552034489104\n",
            "Epoch 12, Loss: 0.029193478712551957\n",
            "Epoch 13, Loss: 0.02573254498063487\n",
            "Epoch 14, Loss: 0.025406967968425214\n",
            "Epoch 15, Loss: 0.02556355595666619\n",
            "Epoch 16, Loss: 0.02197234615766727\n",
            "Epoch 17, Loss: 0.020797824127325972\n",
            "Epoch 18, Loss: 0.019962133656000906\n",
            "Epoch 19, Loss: 0.022260806615202335\n",
            "Epoch 20, Loss: 0.018934740599593835\n",
            "Epoch 21, Loss: 0.0206809796874653\n",
            "Epoch 22, Loss: 0.0195962358218928\n",
            "Epoch 23, Loss: 0.018093306438512244\n",
            "Epoch 24, Loss: 0.02032851512247887\n",
            "Epoch 25, Loss: 0.015233654500376535\n",
            "Epoch 26, Loss: 0.016530532495943814\n",
            "Epoch 27, Loss: 0.01383851719714524\n",
            "Epoch 28, Loss: 0.012799314978452976\n",
            "Epoch 29, Loss: 0.012036695946811062\n",
            "Epoch 30, Loss: 0.010678620977346346\n",
            "Epoch 31, Loss: 0.009204489077883675\n",
            "Epoch 32, Loss: 0.008051800141219395\n",
            "Epoch 33, Loss: 0.008133521133112706\n",
            "Epoch 34, Loss: 0.007773332954510422\n",
            "Epoch 35, Loss: 0.0063868271896490685\n",
            "Epoch 36, Loss: 0.006660345168597339\n",
            "Epoch 37, Loss: 0.003984124852748925\n",
            "Epoch 38, Loss: 0.0036650542742220193\n",
            "Epoch 39, Loss: 0.0027985738380346325\n",
            "Epoch 40, Loss: 0.0018650270071569645\n",
            "Epoch 41, Loss: 0.001649941564978861\n",
            "Epoch 42, Loss: 0.0011309357816351004\n",
            "Epoch 43, Loss: 0.0013234028895274445\n",
            "Epoch 44, Loss: 0.0014623054599328365\n",
            "Epoch 45, Loss: 0.0011005427881568854\n",
            "Epoch 46, Loss: 0.0009601209877325182\n",
            "Epoch 47, Loss: 0.0008184292689357908\n",
            "Epoch 48, Loss: 0.0007582324763320856\n",
            "Epoch 49, Loss: 0.0008242084560117604\n",
            "Epoch 50, Loss: 0.0006992326985009754\n",
            "Task 2 / 2\n",
            "Epoch 1, Loss: 1.6115049439241984\n",
            "Epoch 2, Loss: 1.2703534160415417\n",
            "Epoch 3, Loss: 1.17258798791633\n",
            "Epoch 4, Loss: 1.13900330423533\n",
            "Epoch 5, Loss: 1.1136715580222405\n",
            "Epoch 6, Loss: 1.101697556108818\n",
            "Epoch 7, Loss: 1.0914244024717368\n",
            "Epoch 8, Loss: 1.0767303910793296\n",
            "Epoch 9, Loss: 1.0797955555409\n",
            "Epoch 10, Loss: 1.073223920551143\n",
            "Epoch 11, Loss: 1.068721355171369\n",
            "Epoch 12, Loss: 1.062295883053554\n",
            "Epoch 13, Loss: 1.0626295931685772\n",
            "Epoch 14, Loss: 1.0542285007923649\n",
            "Epoch 15, Loss: 1.0535020044723975\n",
            "Epoch 16, Loss: 1.0420278878377471\n",
            "Epoch 17, Loss: 1.0422185973593574\n",
            "Epoch 18, Loss: 1.040240413842646\n",
            "Epoch 19, Loss: 1.0410188180505584\n",
            "Epoch 20, Loss: 1.0339287725032797\n",
            "Epoch 21, Loss: 1.0306493109839598\n",
            "Epoch 22, Loss: 1.0326785842146635\n",
            "Epoch 23, Loss: 1.0256305560631245\n",
            "Epoch 24, Loss: 1.0175911963891051\n",
            "Epoch 25, Loss: 1.021046869537577\n",
            "Epoch 26, Loss: 1.01679086542957\n",
            "Epoch 27, Loss: 1.010010475967556\n",
            "Epoch 28, Loss: 1.0029233372133879\n",
            "Epoch 29, Loss: 1.0061116239253973\n",
            "Epoch 30, Loss: 1.006573563284057\n",
            "Epoch 31, Loss: 1.0009621182646513\n",
            "Epoch 32, Loss: 0.9941019713232161\n",
            "Epoch 33, Loss: 0.9877660928734471\n",
            "Epoch 34, Loss: 0.9861346528483574\n",
            "Epoch 35, Loss: 0.9823255319140222\n",
            "Epoch 36, Loss: 0.979119393287667\n",
            "Epoch 37, Loss: 0.9734376961135037\n",
            "Epoch 38, Loss: 0.9678969915932016\n",
            "Epoch 39, Loss: 0.9703475287317453\n",
            "Epoch 40, Loss: 0.9658668897157119\n",
            "Epoch 41, Loss: 0.961095748909642\n",
            "Epoch 42, Loss: 0.9566444289141259\n",
            "Epoch 43, Loss: 0.9541935847017615\n",
            "Epoch 44, Loss: 0.9517416908787544\n",
            "Epoch 45, Loss: 0.9516876350255954\n",
            "Epoch 46, Loss: 0.9487215611526092\n",
            "Epoch 47, Loss: 0.9497845196155044\n",
            "Epoch 48, Loss: 0.9448777934992908\n",
            "Epoch 49, Loss: 0.9480652051478818\n",
            "Epoch 50, Loss: 0.9490899818579701\n"
          ]
        }
      ],
      "source": [
        "nb_epochs = 50\n",
        "hoc_loss_vals = compute_loss_values(hoc_enabled=True, nb_epochs=nb_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIwXFBgVlrlL",
        "outputId": "2a943c57-65f8-4648-c5f4-121d7a6bbe87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading Training Dataset\n",
            "Task 1 / 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.6122049743087502\n",
            "Epoch 2, Loss: 0.1020365188241192\n",
            "Epoch 3, Loss: 0.06154970936725602\n",
            "Epoch 4, Loss: 0.05246364099736361\n",
            "Epoch 5, Loss: 0.04172292702222948\n",
            "Epoch 6, Loss: 0.04033395395371634\n",
            "Epoch 7, Loss: 0.03453234896888454\n",
            "Epoch 8, Loss: 0.03248547808954952\n",
            "Epoch 9, Loss: 0.02725426549450923\n",
            "Epoch 10, Loss: 0.029267895493343927\n",
            "Epoch 11, Loss: 0.027146209384120854\n",
            "Epoch 12, Loss: 0.027561268353044194\n",
            "Epoch 13, Loss: 0.02515609479199929\n",
            "Epoch 14, Loss: 0.02241092902609677\n",
            "Epoch 15, Loss: 0.022890164139490597\n",
            "Epoch 16, Loss: 0.022694096365404946\n",
            "Epoch 17, Loss: 0.021932700086615405\n",
            "Epoch 18, Loss: 0.02183882671820984\n",
            "Epoch 19, Loss: 0.01917568504697145\n",
            "Epoch 20, Loss: 0.018957420515872403\n",
            "Epoch 21, Loss: 0.021794592923158145\n",
            "Epoch 22, Loss: 0.018237040974462194\n",
            "Epoch 23, Loss: 0.01583230256853225\n",
            "Epoch 24, Loss: 0.014125189394842313\n",
            "Epoch 25, Loss: 0.014677862483767207\n",
            "Epoch 26, Loss: 0.015189918995674512\n",
            "Epoch 27, Loss: 0.014778690654101902\n",
            "Epoch 28, Loss: 0.011041206413956464\n",
            "Epoch 29, Loss: 0.010182991838367012\n",
            "Epoch 30, Loss: 0.01005798690016776\n",
            "Epoch 31, Loss: 0.011026274882656766\n",
            "Epoch 32, Loss: 0.007893491525114826\n",
            "Epoch 33, Loss: 0.007987181891876693\n",
            "Epoch 34, Loss: 0.007881569701955212\n",
            "Epoch 35, Loss: 0.005960995645285011\n",
            "Epoch 36, Loss: 0.005658795034810187\n",
            "Epoch 37, Loss: 0.005383530885421853\n",
            "Epoch 38, Loss: 0.003973159939758482\n",
            "Epoch 39, Loss: 0.003070838994264484\n",
            "Epoch 40, Loss: 0.002592225814711341\n",
            "Epoch 41, Loss: 0.0021746745249812995\n",
            "Epoch 42, Loss: 0.002052289327682302\n",
            "Epoch 43, Loss: 0.0014550871130199709\n",
            "Epoch 44, Loss: 0.0012386256575950463\n",
            "Epoch 45, Loss: 0.0010860576533114417\n",
            "Epoch 46, Loss: 0.0011006208510689363\n",
            "Epoch 47, Loss: 0.0009487404003643156\n",
            "Epoch 48, Loss: 0.0009093452842751953\n",
            "Epoch 49, Loss: 0.0009050635816983912\n",
            "Epoch 50, Loss: 0.0008566657747240044\n",
            "Task 2 / 2\n",
            "Epoch 1, Loss: 0.36262298635572776\n",
            "Epoch 2, Loss: 0.09773437260627876\n",
            "Epoch 3, Loss: 0.07474251935377701\n",
            "Epoch 4, Loss: 0.06615103547382542\n",
            "Epoch 5, Loss: 0.05702302146904017\n",
            "Epoch 6, Loss: 0.06009097973292859\n",
            "Epoch 7, Loss: 0.05003193497428986\n",
            "Epoch 8, Loss: 0.05177356157004389\n",
            "Epoch 9, Loss: 0.05031601260865709\n",
            "Epoch 10, Loss: 0.03995858397298955\n",
            "Epoch 11, Loss: 0.047913763884489306\n",
            "Epoch 12, Loss: 0.04104992203058881\n",
            "Epoch 13, Loss: 0.04004412918470784\n",
            "Epoch 14, Loss: 0.04146375228186722\n",
            "Epoch 15, Loss: 0.04030749426435966\n",
            "Epoch 16, Loss: 0.03617193719822663\n",
            "Epoch 17, Loss: 0.034924678418291895\n",
            "Epoch 18, Loss: 0.030837267322476887\n",
            "Epoch 19, Loss: 0.032508652063703805\n",
            "Epoch 20, Loss: 0.03091973948725267\n",
            "Epoch 21, Loss: 0.028916904250126527\n",
            "Epoch 22, Loss: 0.03616258774370404\n",
            "Epoch 23, Loss: 0.026129392270400814\n",
            "Epoch 24, Loss: 0.026645690820711703\n",
            "Epoch 25, Loss: 0.031739247236373065\n",
            "Epoch 26, Loss: 0.024403854996546646\n",
            "Epoch 27, Loss: 0.025462365045980904\n",
            "Epoch 28, Loss: 0.02017624005692046\n",
            "Epoch 29, Loss: 0.02359582794623888\n",
            "Epoch 30, Loss: 0.016285045276826032\n",
            "Epoch 31, Loss: 0.017893797485126282\n",
            "Epoch 32, Loss: 0.01714472618347833\n",
            "Epoch 33, Loss: 0.01737679246360529\n",
            "Epoch 34, Loss: 0.013673184371767757\n",
            "Epoch 35, Loss: 0.012217390578840668\n",
            "Epoch 36, Loss: 0.01028955691921956\n",
            "Epoch 37, Loss: 0.010898561299025483\n",
            "Epoch 38, Loss: 0.010522512368305582\n",
            "Epoch 39, Loss: 0.008202178363125532\n",
            "Epoch 40, Loss: 0.005172614582720589\n",
            "Epoch 41, Loss: 0.005443878335565245\n",
            "Epoch 42, Loss: 0.0056431400298606604\n",
            "Epoch 43, Loss: 0.004496484732314621\n",
            "Epoch 44, Loss: 0.0033347630637556207\n",
            "Epoch 45, Loss: 0.0027444239204628\n",
            "Epoch 46, Loss: 0.003342475932854866\n",
            "Epoch 47, Loss: 0.0025949531005537126\n",
            "Epoch 48, Loss: 0.0020206087744935445\n",
            "Epoch 49, Loss: 0.0025049363008261293\n",
            "Epoch 50, Loss: 0.0021419395023795024\n"
          ]
        }
      ],
      "source": [
        "sce_loss_vals = compute_loss_values(hoc_enabled=False, nb_epochs=nb_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "mcB_bHLWoVkt",
        "outputId": "3ff4ad69-4003-4ac8-83e0-298d13013fc8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data (replace with your actual loss values)\n",
        "epochs = range(1, (nb_epochs+1))\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Plot the SCE loss\n",
        "plt.plot(epochs, sce_loss_vals, color='red', label=r'$\\mathcal{L}_{SCE}$', linewidth=2)\n",
        "\n",
        "# Plot the HOC loss\n",
        "plt.plot(epochs, hoc_loss_vals, color='blue', label=r'$\\mathcal{L}_{HOC}$', linewidth=2)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Epochs', fontsize=12)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "\n",
        "# Set the legend with custom formatting\n",
        "plt.legend(fontsize=12, loc='upper right')\n",
        "\n",
        "# Add grid\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBKk2E_duHNN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
